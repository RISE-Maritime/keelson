#!/usr/bin/env python3

import json
import time
import atexit
import logging
import pathlib
import warnings
import argparse
from queue import Queue, Empty
from threading import Thread, Event
from typing import Dict, Tuple
from contextlib import contextmanager

import zenoh
from mcap.writer import Writer
from mcap.well_known import SchemaEncoding, MessageEncoding
from google.protobuf.message import DecodeError


import brefv

logger = logging.getLogger("mcap-record")

BREFV_TO_MCAP_MESSAGE_ENCODING_MAP = {"json": "json", "protobuf": "protobuf"}


@contextmanager
def ignore(*exceptions):
    try:
        yield
    except exceptions:
        logger.exception("Something went wrong in the listener!")

@contextmanager
def mcap_writer(file_handle):
    try:
        writer = Writer(file_handle)
        writer.start()
        logger.info("MCAP writer initilized")
        yield writer
    finally:
        writer.finish()
        logger.info("MCAP writer finished")

def write_message(writer: Writer, channel_id: int, log_time: int, publish_time: int, data: bytes):
    logger.debug("Writing to file: channel_id=%s, log_time=%s, publish_time=%s", channel_id, log_time, publish_time)
    writer.add_message(
        channel_id=channel_id,
        log_time=log_time,
        publish_time=publish_time,
        data=data,
    )

def run(session: zenoh.Session, args: argparse.Namespace):
    queue = Queue()

    close_down = Event()

    def _recorder():

        with args.output.open("wb") as fh, mcap_writer(fh) as writer:

            schemas: Dict[str, Tuple[MessageEncoding, int]] = {}
            channels: Dict[str, int] = {}

            while not close_down.is_set():
                try:
                    sample = queue.get(timeout=0.01)
                except Empty:
                    continue

                with ignore(Exception):
                    topic = str(sample.key_expr)
                    logger.debug("Received sample on topic: %s", topic)

                    # Uncover from brefv envelope
                    try:
                        received_at, enclosed_at, payload = brefv.uncover(
                            sample.value.payload
                        )
                    except DecodeError:
                        logger.exception(
                            "Topic %s did not contain a valid brefv.Envelope: %s",
                            topic,
                            sample.value.payload,
                        )
                        continue

                    # If this topic is known, write message to file
                    if topic in channels:
                        logger.debug(
                            "Topic %s is already known!", topic
                        )
                        write_message(writer, channels[topic], received_at, enclosed_at, payload)
                        continue

                    # Else, lets start finding out about schemas etc
                    try:
                        tag = brefv.get_tag_from_pub_sub_topic(topic)
                    except ValueError:
                        logger.exception(
                            "Received topic did not match the expected format: %s", topic
                        )
                        continue

                    logger.info("Unseen topic %s, adding to file", topic)

                    # IF we havent already got a schema for this tag
                    if not tag in schemas:
                        logger.debug("Tag %s not seen before", tag)

                        match brefv.is_tag_well_known(tag):
                            case True:
                                logger.debug("Tag %s is well-known!", tag)
                                # Get info about the well-known tag
                                brefv_encoding = brefv.get_tag_encoding(tag)
                                brefv_description = brefv.get_tag_description(tag)

                                # Which encoding?
                                match brefv_encoding:
                                    case "protobuf":
                                        logger.debug("...of protobuf encoding.")
                                        file_descriptor_set = brefv.get_protobuf_file_descriptor_set_from_type_name(
                                            brefv_description
                                        )
                                        schemas[tag] = (
                                            MessageEncoding.Protobuf,
                                            writer.register_schema(
                                                name=brefv_description,
                                                encoding=SchemaEncoding.Protobuf,
                                                data=file_descriptor_set.SerializeToString(),
                                            ),
                                        )

                                    case "json":
                                        logger.debug("...of JSON encoding")
                                        schemas[tag] = (
                                            MessageEncoding.JSON,
                                            writer.register_schema(
                                                name=tag,
                                                encoding=SchemaEncoding.JSONSchema,
                                                data=json.dumps(brefv_description).encode(),
                                            ),
                                        )

                                    case _:
                                        logger.error(
                                            "Brefv tag encoding: %s is not supported! Storing without schema.",
                                            brefv_encoding,
                                        )
                                        schemas[tag] = (
                                            "",
                                            writer.register_schema(
                                                name=tag,
                                                encoding=SchemaEncoding.SelfDescribing,
                                                data=b"",
                                            ),
                                        )

                            case False:
                                logger.info(
                                    "Unknown tag, we make a guess on the encoding..."
                                )
                                try:
                                    # We make a guess at JSON, since it is common for rapid prototyping
                                    json.loads(payload)
                                    schemas[tag] = (
                                        MessageEncoding.JSON,
                                        writer.register_schema(
                                            name=tag,
                                            encoding=SchemaEncoding.JSONSchema,
                                            data=b"",
                                        ),
                                    )
                                    logger.debug("...its JSON!")
                                except (json.JSONDecodeError, UnicodeDecodeError):
                                    # Otherwise, we have no idea...
                                    schemas[tag] = (
                                        "",
                                        writer.register_schema(
                                            name=tag,
                                            encoding=SchemaEncoding.SelfDescribing,
                                            data=b"",
                                        ),
                                    )
                                    logger.debug("...no luck, storing without schema.")

                    # Now we have a schema_id, moving on to registering a channel
                    message_encoding, schema_id = schemas[tag]

                    logger.debug(
                        "Registering a channel (%s) with schema_id=%s and message_encoding=%s",
                        topic,
                        schema_id,
                        message_encoding,
                    )

                    channels[topic] = writer.register_channel(
                        topic=topic, message_encoding=message_encoding, schema_id=schema_id
                    )

                    # Finally, put the sample on the queue
                    logger.debug("...and writing the actual message to file!")
                    write_message(writer, channels[topic], received_at, enclosed_at, payload)
        

    t = Thread(target=_recorder)
    t.daemon = True
    t.start()


    # And start subscribing
    subscribers = [session.declare_subscriber(key, queue.put) for key in args.key]

    while True:
        try:
            qsize = queue.qsize()
            logger.debug("Approximate queue size is: %s", qsize)

            if qsize > 100:
                warnings.warn("Queue size is %s", qsize)
            elif qsize > 1000:
                raise RuntimeError(
                    f"Recorder is not capable of keeping up with data flow. Current queue size is {qsize}. Exiting!"
                )
            
            time.sleep(1.0)
        except KeyboardInterrupt:
            logger.info("Closing down on user request!")
            logger.debug("Undeclaring subscribers...")
            for sub in subscribers:
                sub.undeclare()

            logger.debug("Waiting for all items in queue to be processed...")
            while not queue.empty():
                time.sleep(0.1)

            logger.debug("Joining recorder thread...")
            close_down.set()
            t.join()

            logger.debug("Done! Good bye :)")
            break


def main():
    parser = argparse.ArgumentParser(
        prog="record",
        description="A pure python mcap recorder for keelson",
        formatter_class=argparse.ArgumentDefaultsHelpFormatter,
    )

    parser.add_argument("--log-level", type=int, default=logging.INFO)

    parser.add_argument(
        "-k",
        "--key",
        type=str,
        action="append",
        required=True,
        help="Key expressions to subscribe to from the Zenoh session",
    )

    parser.add_argument(
        "-o",
        "--output",
        type=pathlib.Path,
        required=True,
        help="File path to write recording to",
    )

    ## Parse arguments and start doing our thing
    args = parser.parse_args()

    # Setup logger
    logging.basicConfig(
        format="%(asctime)s %(levelname)s %(name)s %(message)s", level=args.log_level
    )
    logging.captureWarnings(True)
    zenoh.init_logger()

    # Put together zenoh session configuration
    conf = zenoh.Config()
    conf.insert_json5(zenoh.config.MODE_KEY, json.dumps("peer"))

    ## Construct session
    logger.info("Opening Zenoh session...")
    session = zenoh.open(conf)

    def _on_exit():
        session.close()

    atexit.register(_on_exit)

    run(session, args)


if __name__ == "__main__":
    main()
